<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: scala | Karol Stasiak's Blog]]></title>
  <link href="http://KarolS.github.io/categories/scala/atom.xml" rel="self"/>
  <link href="http://KarolS.github.io/"/>
  <updated>2014-04-29T01:21:22+02:00</updated>
  <id>http://KarolS.github.io/</id>
  <author>
    <name><![CDATA[Karol Stasiak]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Random ideas for Scala 3.0]]></title>
    <link href="http://KarolS.github.io/blog/2014/04/29/random-ideas-for-scala-3-0/"/>
    <updated>2014-04-29T01:22:00+02:00</updated>
    <id>http://KarolS.github.io/blog/2014/04/29/random-ideas-for-scala-3-0</id>
    <content type="html"><![CDATA[<p>Here comes a list of things that I would love to see in Scala 3.0. Some of them are breaking changes, hence 3.0 not 2.13 or anything like that. Some of them are about the compiler, some of them are about the library, some of them are about the external tools. Some of those ideas are different solutions for the same problem.</p>

<!-- more -->

<h3 id="syntax">Syntax</h3>

<ul>
  <li>
    <p>Treating number literals with leading zeroes as decimal (with a warning for a version or two).</p>
  </li>
  <li>
    <p>Binary and octal literals in forms of <code>0b01010101</code> and <code>0o037</code>.</p>
  </li>
  <li>
    <p>Underscores in numeric literals: <code>1_000_000</code>.</p>
  </li>
  <li>
    <p>Some kind of byte array literal.</p>
  </li>
  <li>
    <p><code>BigInt</code> and <code>BigDecimal</code> literals: <code>100000000000000000000000000000000000N</code>, <code>0.01m</code></p>
  </li>
  <li>
    <p><code>Short</code> and <code>Byte</code> literals, both accepting both signed and unsigned values: <code>20000s</code>, <code>255y</code></p>
  </li>
  <li>
    <p>Removal of XML literals and an <code>xml</code> macro string context as a replacement: <code>xml"&lt;p&gt;Hello $world&lt;/p&gt;"</code></p>
  </li>
  <li>
    <p>Introducing true <code>break</code>, <code>continue</code> and <code>goto</code>.</p>
  </li>
  <li>
    <p>A special syntax for monads, like Haskell’s <code>do</code>.</p>

    <ul>
      <li>
        <p><code>do</code> is already a keyword, it can cause problems with <code>do...while</code> loops.</p>
      </li>
      <li>
        <p><code>for</code> is clunky, especially when it comes to <code>if...else</code>. Maybe fix <code>for</code>?</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="standard-library">Standard library</h3>

<ul>
  <li>
    <p>Clean-up of the collections. Currently, the standard collections are a little mess. I think <a href="http://www.slideshare.net/extempore/a-scala-corrections-library">Paul Phillips sums it up nicely</a>.</p>
  </li>
  <li>
    <p>Standard <code>scala-time</code> library, being a wrapper for both Joda Time and Java 8 Time API.</p>

    <ul>
      <li>There would be two functionally identical implementations.</li>
    </ul>
  </li>
  <li>
    <p>HLists.</p>
  </li>
  <li>
    <p>Vectors with length known at compile-time.</p>
  </li>
  <li>
    <p>A macro that includes C header files on compile time and generates corresponding JNA interfaces.</p>
  </li>
  <li>
    <p>Removal of <code>/:</code> and <code>:\</code> methods.</p>
  </li>
  <li>
    <p>A clone of .NET’s <code>dynamic</code> type.</p>
  </li>
  <li>
    <p><code>String.toInt</code> and friends accepting a base.</p>
  </li>
  <li>
    <p>A <code>^</code> operator for sets, returning the symmetric difference.</p>
  </li>
</ul>

<h3 id="value-classes">Value classes</h3>

<ul>
  <li>
    <p>Specialization for custom value classes.</p>
  </li>
  <li>
    <p>Generating specialized classes on the fly by the compiler (so the compiler would take an existing class, either ours or from an external library, and specialize it).</p>

    <ul>
      <li>This would allow to specialize collections.</li>
    </ul>
  </li>
  <li>
    <p>Unboxed arrays for custom value classes.</p>
  </li>
  <li>
    <p>Different name mangling for methods taking value classes.</p>

    <ul>
      <li>Currently, if you have <code>class A(x: Int) extends AnyVal</code>, <code>class B(x: Int) extends AnyVal</code> and try to write both <code>def method(a: A)</code> and <code>def method(b: B)</code>, you get an error.</li>
    </ul>
  </li>
  <li>
    <p>Multi-field value classes.</p>

    <ul>
      <li>
        <p>This could work as following: if the value is a field, a local variable, or a parameter, use several variables. If it’s a return value, box it.</p>
      </li>
      <li>
        <p>This of course wouldn’t improve performance much, unless there would be an alternative way to return such values.</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="type-system">Type system</h3>

<ul>
  <li>
    <p>Almost full type inference for private and local functions and variables.</p>
  </li>
  <li>
    <p>Built-in type-level integers, booleans and strings, with some operations on them.</p>
  </li>
  <li>
    <p>Compile-time null safety – detection of provable paths that could potentially lead to NPE’s.</p>
  </li>
  <li>
    <p>Multimethods.</p>
  </li>
</ul>

<h3 id="fixing-minor-annoyances">Fixing minor annoyances</h3>

<ul>
  <li>
    <p>Adding Scalaz’s <code>some</code> and <code>none</code>.</p>
  </li>
  <li>
    <p>Adding Scalaz’s <code>Equal</code> and <code>Monoid</code> typeclasses.</p>
  </li>
  <li>
    <p><code>@adt</code> annotation on a trait would make the generated <code>apply</code> method of companion objects of case classes that implement that trait return that trait.</p>

    <ul>
      <li>
        <p>For example, annotating <code>Option</code> with <code>@adt</code> and writing <code>var x = Some(1)</code> would make <code>x</code> of type <code>Option[Int]</code>, not <code>Some[Int]</code>.</p>
      </li>
      <li>
        <p>It would be nice to make it somehow work with case objects, especially in polymorphic cases, like with <code>Option</code> and <code>None</code>, or <code>Either</code> and either <code>Left</code> or <code>Right</code> (either of these fixes only one type parameter, not two).</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Ignoring missing annotation definitions in external libraries.</p>
  </li>
  <li>
    <p>Allowing for creating annotations with runtime retention in Scala.</p>
  </li>
</ul>

<h3 id="tooling">Tooling</h3>

<ul>
  <li>
    <p>A decent, officially supported Findbugs plugin.</p>
  </li>
  <li>
    <p>A configurable style checker, preferably including <a href="http://www.scala-lang.org/old/node/8610">“powerlevels”</a>.</p>
  </li>
  <li>
    <p>A Java-to-idiomatic-Scala converter.</p>
  </li>
  <li>
    <p>A Scala-to-idiomatic-Java converter.</p>
  </li>
  <li>
    <p>Easier developing for Android.</p>

    <ul>
      <li>
        <p>Built-in Proguard-like optimizer?</p>
      </li>
      <li>
        <p>Dalvik backend?</p>
      </li>
    </ul>
  </li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Units 0.1 released]]></title>
    <link href="http://KarolS.github.io/blog/2014/01/02/units-0-1-released/"/>
    <updated>2014-01-02T20:26:00+01:00</updated>
    <id>http://KarolS.github.io/blog/2014/01/02/units-0-1-released</id>
    <content type="html"><![CDATA[<p>After several months of not-so-intensive work, I present the version 0.1 of the <em>Units</em> library: <a href="https://github.com/KarolS/units">https://github.com/KarolS/units</a>.</p>

<p><em>Units</em> is a Scala library for providing type-level units of measurements checked on compile time. The goal of the library was to provide as seamless as possible way to check if the units used in arithmetic expressions are correct.</p>

<p><em>If you have tried to compile it: Yes it does compile that long. A clean build takes 100 seconds on my i7.</em></p>

<p>Compile-time unit checking has multiple applications:</p>

<ul>
  <li>
    <p>scientists will be able to distinguish values in metres per second, metres, metres per second squared <a href="http://en.wikipedia.org/wiki/Mars_Climate_Orbiter">instead of crashing expensive space exploration equipment</a> or <a href="https://www.ismp.org/newsletters/acutecare/articles/A3Q99Action.asp">drugging a patient</a></p>
  </li>
  <li>
    <p>engineers will be able to distinguish values in metres, centimetres, feet, inches, litres, gallons <a href="http://en.wikipedia.org/wiki/Air_Canada_Flight_143">instead of running out of fuel in the middle of a flight</a> or <a href="http://spectrum.ieee.org/tech-talk/at-work/test-and-measurement/columbuss-geographical-miscalculations">thinking the distance to travel is many times shorter</a></p>
  </li>
  <li>
    <p>designers will be able to distinguish values in millimetres, inches, pixels, points</p>
  </li>
  <li>
    <p>economists will be able to distinguish values in euros, dollars, dollars per hour, ounces of gold</p>
  </li>
  <li>
    <p>game developers will be able to distinguish values in pixels, tiles, damage points, minerals, barrels of vespen gas</p>
  </li>
  <li>
    <p>network software developers will be able to distinguish values in kilobytes, kibibytes, kilobits, kilobits per second</p>
  </li>
  <li>
    <p>and so on and on</p>
  </li>
</ul>

<p>There are not many languages with units of measurement support, the first that comes to mind is <a href="http://msdn.microsoft.com/en-us/library/dd233243.aspx">F#</a>. I must admit that it is great at this. There also other languages that support units as a first-class language feature, and many that support units with a library. Those libraries vary in their expressibility and versatility, some of them only allow SI units, some of them require you to explicitly express relations between multiplied values, and some of them only support a limited subset of units. There have been earlier Scala libraries with units of measurements, but they all had severe limitations. <em>Units</em> library tries to be both expressive and versatile. While it’s not as powerful as F# built-in unit support, it definitely allows for quite a bit.</p>

<p>Enough of that, time for some examples that will showcase the main features.</p>

<!-- more -->

<p>Let’s start with something simple:</p>

<p>```scala</p>

<p>import io.github.karols.units._
import io.github.karols.units.SI._</p>

<p>val length1 = 1.of[metre]
val length2 = 2.of[metre]
val area1 = 1.of[square[metre]]
val area2 = length1 * length2 </p>

<p>length1 &lt; length2 // OK
area1 + area2 //OK
area1 + length2 // not OK, compile time error</p>

<p>```</p>

<p>The main difference you see is that all the values have a unit defined. The type of the variables in this example is <code>IntU[metre]</code> and <code>IntU[square[metre]]</code> respectively. It is an <code>AnyVal</code> wrapping a 64-bit <code>Long</code>. There is also <code>DoubleU</code>, which wraps 64-bit <code>Double</code>.</p>

<p>The library supports out-of-the-box most SI units, some Imperial and US Customary units, units of information and bandwidth, and many currencies. Most of the units can be semi-automatically converted, i.e. the following code:</p>

<p>```scala
def printMM(length: DoubleU[millimetre]) = {
  println(s”The length is $length mm.”)
}</p>

<p>printMM(1.of[inch].convert)</p>

<p>printMM(1.of[metre] + 1.of[millimetre])
```</p>

<p>will correctly print </p>

<p><code>
The length is 25.4 mm.
The length is 1001.0 mm.
</code></p>

<h3 id="implementation">Implementation</h3>

<p>How does it work, you ask. It’s simple. Down deep in the guts of the library, there lurks an implementation of a type-level map from strings to integers, with the following properties:</p>

<ul>
  <li>
    <p>strings are sorted lexicographically (so the equality can be structural)</p>
  </li>
  <li>
    <p>no integer value is equal to zero (so units to the zeroth power don’t matter)</p>
  </li>
</ul>

<p>For example, the above units are represented as <code>{"m" -&gt; 1}</code> and <code>{"m" -&gt; 2}</code> respectively.</p>

<p>You are probably curious how type-level datatypes are defined. I admit that they are implemented pretty simply. Here are <a href="https://github.com/KarolS/units/blob/master/units/src/main/scala/internal/Bools.scala">booleans</a>, here <a href="https://github.com/KarolS/units/blob/master/units/src/main/scala/internal/Integers.scala">integers</a>, here <a href="https://github.com/KarolS/units/blob/master/units/src/main/scala/internal/Strings.scala">characters and strings</a>, here <a href="https://github.com/KarolS/units/blob/master/units/src/main/scala/internal/SingleUnits.scala">unit names</a> and here <a href="https://github.com/KarolS/units/blob/master/units/src/main/scala/internal/UnitImpl.scala">unit maps</a>.</p>

<p>I’ll focus here on integers, because they’re simple enough to explain. Here’s the code (slightly simplified):</p>

<p>```scala</p>

<p>sealed trait TInteger {
    type Succ &lt;: TInteger
    type Pred &lt;: TInteger
    type Negate &lt;: TInteger
    type Add[X&lt;:TInteger] &lt;: TInteger
    type Mul[X&lt;:TInteger] &lt;: TInteger
    type ZeroNegPos[IfZero&lt;:ResultType, IfNeg[N&lt;:TInteger]&lt;:ResultType, IfPos[N&lt;:TInteger]&lt;:ResultType, ResultType] &lt;: ResultType
    type Equal[X&lt;:TInteger] &lt;: TBool
}
type LambdaNatFalse[N&lt;:TInteger] = False
sealed trait _0 extends TInteger {
    type Succ = Inc[_0]
    type Pred = Dec[_0]
    type Negate = _0
    type Add[X&lt;:TInteger] = X
    type Mul[X&lt;:TInteger] = _0
    type ZeroNegPos[IfZero&lt;:ResultType, IfNeg[N&lt;:TInteger]&lt;:ResultType, IfPos[N&lt;:TInteger]&lt;:ResultType, ResultType] = IfZero
    type Equal[X&lt;:TInteger] &lt;: X#ZeroNegPos[True, LambdaNatFalse, LambdaNatFalse, TBool]
}
sealed trait Inc[N &lt;: TInteger] extends TInteger {
    type Succ = Inc[Inc[N]]
    type Pred = N
    type Negate = Dec[N#Negate]
    type Add[X&lt;:TInteger] = N#Add[X#Succ]
    type Mul[X&lt;:TInteger] = N#Mul[X]#Add[X]
    type ZeroNegPos[IfZero&lt;:ResultType, IfNeg[N&lt;:TInteger]&lt;:ResultType, IfPos[N&lt;:TInteger]&lt;:ResultType, ResultType] = IfPos[N]
    type Equal[X&lt;:TInteger] &lt;: X#ZeroNegPos[False, LambdaNatFalse, N#Equal, TBool]
}
sealed trait Dec[N &lt;: TInteger] extends TInteger {
    type Succ = N
    type Pred = Dec[Dec[N]]
    TInteger]
    type Negate = Inc[N#Negate]
    type Add[X&lt;:TInteger] = N#Add[X#Pred]
    type Mul[X&lt;:TInteger] = N#Mul[X]#Add[X#Negate]
    type ZeroNegPos[IfZero&lt;:ResultType, IfNeg[N&lt;:TInteger]&lt;:ResultType, IfPos[N&lt;:TInteger]&lt;:ResultType, ResultType] = IfNeg[N]
    type Equal[X&lt;:TInteger] &lt;: X#ZeroNegPos[False, N#Equal, LambdaNatFalse, TBool]
}
```
As you can see:</p>

<ul>
  <li>
    <p>The code looks like normal code, but with <code>type</code> instead of <code>def</code> and with <code>Object#Method[Param]</code> instead of <code>object.method(param)</code>.</p>
  </li>
  <li>
    <p><code>_0</code> is the type-level zero, <code>Dec</code> is a type-level negative number, and <code>Inc</code> is a type-level positive number.</p>
  </li>
  <li>
    <p><code>Succ</code> and <code>Pred</code> are successor and predecessor respectively;</p>
  </li>
  <li>
    <p><code>Negate</code>, <code>Add</code> and <code>Mul</code> are defined recursively in a pretty straightforward way.</p>
  </li>
  <li>
    <p><code>ZeroNegPos</code> is integer pattern matching. It’s explicitly polymorphic. It takes four parameters: the result for when the number is zero, the function for when the number is positive, the function for when the number is negative, and the result type. If the result is zero, the first parameter is returned. If it’s not, the correct function is applied to the underlying value (the integer that is closer to zero), yielding the result. For example, let’s have a look at <code>Inc#Equal</code>: <code>type Equal[X&lt;:TInteger] &lt;: X#ZeroNegPos[False, LambdaNatFalse, N#Equal, TBool]</code></p>

    <ul>
      <li>
        <p>if <code>X</code> is <code>_0</code>, returns <code>False</code></p>
      </li>
      <li>
        <p>if <code>X</code> is <code>Dec[Y]</code>, returns <code>LambdaNatFalse[Y]</code>, i.e. <code>False</code></p>
      </li>
      <li>
        <p>if <code>X</code> is <code>Inc[Y]</code>, returns <code>N#Equal[Y]</code> (a recursive call)</p>
      </li>
    </ul>
  </li>
</ul>

<p>(<code>True</code> and <code>False</code> are type-level booleans)</p>

<p>Type-level strings are defined using a custom type-level encoding that supports only ASCII letters and several symbols useful for defining units (including the degree sign <code>°</code> and capital omega <code>Ω</code>).</p>

<p>You can probably guess how the arithmetic works:</p>

<ul>
  <li>
    <p>adding and subtracting values requires both units to match</p>
  </li>
  <li>
    <p>multiplying causes the values with the same keys be added together</p>
  </li>
  <li>
    <p>dividing causes the values with the same keys be subtracted</p>
  </li>
  <li>
    <p>all missing keys in the unit map have value zero</p>
  </li>
  <li>
    <p>if after adding or subtracting you get zero, you remove the key</p>
  </li>
</ul>

<h3 id="defining-units">Defining units</h3>

<p>Defining your own units is quite easy. The most basic thing you have to do is to define a unit and its type-level string. The string will be used to display the name of the unit (so better pick something that makes sense), but also to distinguish units themselves (so better pick something unique).</p>

<p>```scala
import io.github.karols.units._
import io.github.karols.units.defining._</p>

<p>type fortnight = DefineUnit[_f ~: _o ~: _r ~: _t ~: _n ~: _i ~: _g ~: _h ~: _t]
```</p>

<p>That’s it!</p>

<p>You can also define some conversions:</p>

<p>```scala
import io.github.karols.units.SI._</p>

<p>implicit val fortnight_to_day = one[fortnight].contains(14)[day]</p>

<p>println((1.of[fortnight] + 3.of[day]).mkString) // prints “17 d”
```</p>

<p>Sadly, you need to define conversions from fortnights to other units manually, and then you’ll have to define conversions of compound units, like from <em>mile/fortnight</em> to <em>kilometre/day</em>. The ratios have several operators defined to help with this, consult the documentation and source for more info.</p>

<h3 id="affine-spaces">Affine spaces</h3>

<p>The library preserves also another distinction: between normal values with units and elements of affine spaces. Affine spaces (also known as torsor spaces) are spaces that contain elements that cannot be added or multiplied, because those operations make no sense. For example, temperature is such space: there’s no reason to say “yesterday it was 3°C, today it’s 8°C, the sum of these is 11°C”. For these applications, the library provides <code>IntA</code> and <code>DoubleA</code> types. Subtracting two values of such type (using <code>--</code> operator) yields a value of <code>IntU</code> or <code>DoubleU</code> type, which we can call here the difference type.</p>

<p>The affine spaces often have an arbitrarily selected zero point. The zero point has no special properties, unlike the zero element of a vector space. It’s simply chosen to provide people a frame of reference.</p>

<p>Some examples of affine spaces, their zero points, and their difference spaces:</p>

<ul>
  <li>
    <p>temperature is an affine space, its zero point is the temperature of zero degrees, and its difference space is the space of temperature differences</p>
  </li>
  <li>
    <p>timestamps form an affine space, its zero point is an arbitrary moment in time (usually first midnight of the 1st day of January 1900, 1904, 1970, or 2000), and its difference space is time</p>
  </li>
  <li>
    <p>positions form an affine space, its zero point is usually called an origin, and its difference space is the corresponding vector space</p>
  </li>
</ul>

<p>Adding or multiplying temperatures, timestamps or positions doesn’t make sense. Adding to them a value from the corresponding difference space (this value is usually called an displacement) makes sense and yields another value from the affine space.</p>

<p><em>Units</em> library suggests using <code>IntA</code> and <code>DoubleA</code> for values from affine spaces and <code>IntU</code> and <code>DoubleU</code> for values from difference spaces.</p>

<p>Out-of-the-box <em>Units</em> defines Celsius and Fahrenheit scales and Unix timestamps in second, millisecond and nanosecond precisions.</p>

<h3 id="arrays">Arrays</h3>

<p>In Scala, the only unboxed collection types are arrays of primitive types. So all the other collections, and also arrays of custom value classes, are boxed. This leads to serious performance implications. You may think it would be easier to just use non-type safe code and revert back to raw doubles and longs.</p>

<p>To prevent this, the <em>Units</em> library provides array classes for <code>DoubleU</code>, <code>IntU</code>, <code>DoubleA</code> and <code>IntA</code>. According to few simple benchmarks that are available, the classes <code>DoubleUArray</code>, <code>IntUArray</code>, <code>DoubleAArray</code> and <code>IntAArray</code> are as fast as raw <code>Array[Double]</code> and <code>Array[Long]</code>.</p>

<p>Besides, you might have asked before:</p>

<blockquote>
  <p>Hey, you <strong>can</strong> add temperatures, provided you divide them immediately afterwards to get an average!</p>
</blockquote>

<p>All of these array classes provide an <code>avg</code> method, so you can write:</p>

<p>```scala
val t1 = 3.at[CelsiusScale]
val t2 = 8.at[CelsiusScale]</p>

<p>val average = IntAArray(t1,t2).avg</p>

<p>println(average.mkString) // prints 5.5 °C
```</p>

<h3 id="and-theres-more">And there’s more!</h3>

<p>The <em>Units</em> library also supports 2D and 3D vectors (both normal and affine), unboxed efficient vector arrays, semi-automatic affine space conversions, various ways to express functions with unit polymorphism (sadly, none of them as clean as in F#) and interoperability layers for many libraries (Scalaz, Spire, Slick, JodaTime, Algebird, Scalacheck, more to come).</p>

<p>The next goal is to get it to Sonatype.</p>

]]></content>
  </entry>
  
</feed>
